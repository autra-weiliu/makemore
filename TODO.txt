### TODOs
[x] implement bigram test   
[ ] multigram mlp test   
[ ] replace `loss.backward()` with manually gradient calculation, purely step by step gradient calculation and topologicial sort based
gradient calculation   
